### 什么是负载均衡？
假设现在只有一个窗口、一个收银员：
1 一般情况下，收银员平均 2 分钟服务一位顾客，10 分钟可以服务 5 位顾客；  
2 到周末高峰期时，收银员加快收银，平均 1 分钟服务一位顾客，10 分钟最多服务 10 位顾客，也就是说一个顾客最多等待 10 分钟；  
3 逢年过节，顾客数量激增，一下增加到 30 位顾客，如果仍然只有一个窗口和一个收银员，那么所有顾客就只能排队等候了，一个顾客最多需要等待 30 分钟。这样购物体验，就非常差了。  

当然有。那就是新开一个收银窗口，每个收银窗口服务 15 个顾客，这样最长等待时间从 30 分钟缩短到 15 分钟。但如果，这两个窗口的排
队顾客数严重不均衡，比如一个窗口有 5 个顾客排队，另一个窗口却有 25 个顾客排队，就不能最大化地提升顾客的购物体验。  

通常情况下，`负载均衡可以分为两种`：
+ 一种是请求负载均衡，即将用户的请求均衡地分发到不同的服务器进行处理；  
+ 另一种是数据负载均衡，即将用户更新的数据分发到不同的存储服务器。  

#### 服务请求的负载均衡方法
> 通常情况下，计算机领域中，在不同层有不同的负载均衡方法。比如，从`网络层的角度`，通常有基于 DNS、IP 报文等的负载均衡方法；`在
> 中间件层`（也就是我们专栏主要讲的分布式系统层），常见的负载均衡策略主要包括轮询策略、随机策略、哈希和一致性哈希等策略
##### 轮询策略
轮询策略是一种实现简单，却很常用的负载均衡策略，核心思想是服务器轮流处理用户请求，以尽可能使每个服务器处理的请求数相同。生活中
也有很多类似的场景，比如，学校宿舍里，学生每周轮流打扫卫生，就是一个典型的轮询策略

###### 在负载均衡领域中，轮询策略主要包括顺序轮询和加权轮询两种方式。
+ 顺序轮询 
> 假设有 6 个请求，编号为请求 1~6，有 3 台服务器可以处理请求，编号为服务器 1~3，如果采用顺序轮询策略，则会按照服务器 1、2、3 的顺序轮流进行请求。
> 将 6 个请求当成 6 个步骤
```
> 1 请求 1 由服务器 1 处理
> 2 请求 2 由服务器 2 处理。
> 3 请求 3 由服务器 3 处理
> 4 请求 4 由服务器 1 处理
> 5 请求 5 由服务器 2 处理
> 6 请求 6 由服务器 3 处理
```

+ 加权轮询
加权轮询为每个服务器设置了优先级，每次请求过来时会挑选优先级最高的服务器进行处理。比如服务器 1~3 分配了优先级{4，1，1}，这 6 个请求到来时，还当成 6 个步骤，如表所示。
```
> 1 {4，1，1}请求 1 由优先级最高的服务器 1 处理，服务器 1 的优先级相应减 1，此时各服务器优先级为{3，1，1}；
> 2 {3，1，1}请求 1 由优先级最高的服务器 1 处理，服务器 1 的优先级相应减 1，此时各服务器优先级为{2，1，1}；
> 3 {2，1，1}请求 1 由优先级最高的服务器 1 处理，服务器 1 的优先级相应减 1，此时各服务器优先级为{1，1，1}；
> 4 {1，1，1}请求 1 由优先级最高的服务器 1 处理，服务器 1 的优先级相应减 1，此时各服务器优先级为{0，1，1}；
> 5 {0，1，1}请求 1 由优先级最高的服务器 1 处理，服务器 2 的优先级相应减 1，此时各服务器优先级为{0，0，1}；
> 6 {0，0，1}请求 1 由优先级最高的服务器 1 处理，服务器 3 的优先级相应减 1，此时各服务器优先级为{0，0，0}；
```

+ Nginx 平滑的加权轮询策略
 `Nginx 默认的负载均衡策略就是一种改进的加权轮询策略, 解释下 Nginx 轮询策略需要用到的变量`
 1 weight：配置文件中为每个服务节点设置的服务节点权重，固定不变  
 2 effective_weight: 服务节点的有效权重，初始值为 weight。 在 Nginx 的源码中有一个最大失败数的变量 max_fails，当服务发生异
 常时，则减少相应服务节点的有效权重, 公式为 effective_weight = effective_weight - weight / max_fails,  之后再次选取本节点，
 若服务调用成功，则增加有效权重，effective_weight ++ ，直至恢复到 weight  
 3 current_weight: 服务节点当前权重，初始值均为 0，之后会根据系统运行情况动态变化。  
 
 假设，各服务器的优先级是{4，1，1}，还是将 6 个请求分为 6 步来进行讲解
 ```
> 1 遍历集群中所有服务节点，使用 current_weight = current_weight + effective_weight，计算此时每个服务节点的 current_weight，
  得到 current_weight 为{4，1，1}, total 为 4+1+1=6, 选出 current_weight 值最大的服务节点即服务器 1 来处理请求, 随后服务器 1 
  对应的 current_weight 减去此时的 total 值，即 4 - 6，变为了 -2 。{-2， 1， 1}
> 2 按照上述步骤执行，首先遍历，按照 current_weight = current_weight + effective_weight 计算每个服务节点 current_weight 的
 值，结果为{2，2，2}`(源于{-2, 1, 1} + {4, 1, 1})`，total 为 6，选出 current_weight 值最大的服务节点。current_weight 最大值有多个服务节点时，直接选择第一个
 节点即可，在这里选择服务器 1 来处理请求，随后服务器 1 对应的 current_weight 值减去此时的 total，即 2 - 6，结果为 -4, {-4, 2, 2}
> 3 {0, 3, 3}`(源于{-4, 2, 2} + {4, 1, 1})`, 服务器2处理请求， current_weight值减去此时的 total 6， {0， -3， 3}
> 4 {4, -2, 4}`(源于{0， -3， 3} + {4, 1, 1})`, 服务器1处理请求,current_weight值减去此时的 total 6, {-2, -2, 4}
> 5 {2, -1, 5}`(源于{-2, -2, 4} + {4, 1, 1})`, 服务器3处理请求,current_weight值减去此时的 total 6, {2, -1, -1}
> 6 {6, 0, 0}`(源于{2, -1, -1} + {4, 1, 1})`, 服务器1处理请求,current_weight值减去此时的 total 6, {0, 0, 0}
```

可以看到，与普通的加权轮询策略相比，这种轮询策略的优势在于，当部分请求到来时，不会集中落在优先级较高的那个服务节点。

还是上面的例子，假设只有 4 个请求，按照普通的加权轮询策略，会全部由服务器 1 进行处理，即{1,1,1,1}；而按照这种平滑的加权轮询
策略的话，会由服务器 1 和 2 共同进行处理，即{1,1,2,1}。

`轮询策略的优点`就是，实现简单，且对于请求所需开销差不多时，负载均衡效果比较明显，同时加权轮询策略还考虑了服务器节点的异构性，即可
以让性能更好的服务器具有更高的优先级，从而可以处理更多的请求，使得分布更加均衡。

`轮询策略的缺点`是，每次请求到达的目的节点不确定，不适用于有状态请求的场景。并且，轮询策略主要强调请求数的均衡性，所以不适用于处理
请求所需开销不同的场景。 <font color='red'>`综上所述，轮询策略适用于用户请求所需资源比较接近的场景`</font>。

+ 随机策略
随机策略也比较容易理解，指的就是当用户请求到来时，会随机发到某个服务节点进行处理，可以采用随机函数实现。这里，随机函数的作用就
是，让请求尽可能分散到不同节点，防止所有请求放到同一节点或少量几个节点上。

`随机策略适用于，集群中服务器节点处理能力相差不大，用户请求所需资源比较接近的场景`。

+ 哈希和一致性哈希策略
`哈希与一致性策略的优点是`，哈希函数设置合理的话，负载会比较均衡。而且，相同 key 的请求会落在同一个服务节点上，可以用于有状态请求的
场景。除此之外，带虚拟节点的一致性哈希策略还可以解决服务器节点异构的问题。

`但其缺点是`，当某个节点出现故障时，采用哈希策略会出现数据大规模迁移的情况，采用一致性哈希策略可能会造成一定的数据倾斜问题。同
样的，这两种策略也没考虑请求开销不同造成的不均衡问题。

### 什么是流量控制？
比如，类似双十一、双十二的秒杀场景，用户流量突增时，即使做了负载均衡，我们仍然会感受到点击抢购时，需要等待较长的时间。这背后的
原理是什么呢？

这是因为系统控制了用户的请求量

双十一、双十二秒杀场景中，用户流量突增，在这种高并发、大流量的情况下，服务器的处理能力成为电商系统的瓶颈，处理不好就会导致系统
崩溃，服务不可用。而分布式系统中的流量控制，就是解决这类问题的一种关键技术。

通俗地说，分布式流量控制就是在分布式系统下，控制每个服务器接收的请求数，以保证服务器来得及处理这些请求，也就是说尽可能保证用户请
求持续地被处理，而不是让大量的用户请求“阻塞”在服务器中，等待被执行

#### 分布式系统流量控制策略
##### 漏桶策略
漏桶策略借鉴上述原理，无论用户请求有多少，无论请求速率有多大，“漏桶”都会接收下来，但从漏桶里出来的请求是固定速率的，保证服务器可
以处理得游刃有余。当“漏桶”因为容量限制放不下更多的请求时，就会选择丢弃部分请求。这种思路其实就是一种“宽进严出”的策略。

这种策略的`好处`是，做到了流量整形，即无论流量多大，即便是突发的大流量，输出依旧是一个稳定的流量。但其`缺点`是，对于突发流量的情况，
因为服务器处理速度与正常流量的处理速度一致，会丢弃比较多的请求。`但是，当突发大流量到来时，服务器最好能够更快地处理用户请求，这
也是分布式系统大多数情况下想要达到的效果`。

`漏桶策略适用于间隔性突发流量且流量不用即时处理的场景`

##### 令牌桶策略
令牌桶策略，也是一个很形象的名字，指的是桶里放着很多令牌，请求只有拿到令牌才能被服务器处理。

有一个固定容量的存放令牌的桶，我们以固定速率向桶里放入令牌，桶满时会丢弃多出的令牌。每当请求到来时，必须先到桶里取一个令牌才可被
服务器处理，也就是说只有拿到了令牌的请求才会被服务器处理。所以，你可以将令牌理解为门卡，只有拿到了门卡才能顺利进入房间。

令牌以每秒 3 个的速率放入到令牌桶中，桶的容量为 10。通常情况下， 每秒会有 2 个用户请求，请求到来时就会到桶里取一个令牌，由于请求
的速率低于放令牌的速率，因此令牌桶里令牌会逐渐增多，直到达到桶的容量。超过桶容量后，令牌会被丢弃。

当大流量到来时，比如某个时刻来了 10 个请求，此时桶里有 10 个令牌，因此，请求都会被服务器处理；但如果来的请求数不止 10 个，令牌会
被取完，多余的请求取不到令牌，也就没办法及时被服务器处理，需要等待令牌。

通过上述的例子，就能看出这种策略的`好处`：当有突发大流量时，只要令牌桶里有足够多的令牌，请求就会被迅速执行。通常情况下，令牌桶容
量的设置，可以接近服务器处理的极限，这样就可以有效利用服务器的资源。因此，这种策略`适用于有突发特性的流量，且流量需要即时处理的场景`。

Google 开源工具包 Guava 提供的限流工具类 RateLimiter，就是基于令牌桶算法来完成限流的。


> 阿里开源的流量控制框架 Sentinel 可以了解一下， 不多做解释

### 什么是故障隔离？
在双十一的抢购高峰期，如果分布式系统不能满足高可用的特性，那么当大量用户同时抢购时就可能导致系统崩溃，无法提供服务，导致大量用户流失。

从字面意思来看，故障隔离就是，把故障通过某种方式与其他正常模块进行隔离，以保证某一模块出现故障后，不会影响其他模块。

`其实，我们生活有很多故障隔离的例子`，比如交通。`一辆车就类似于分布式系统中的一个模块，当一辆车在高速公路上出现故障后，我们通常会将
其停靠在紧急车道，或者在其前后设置故障指示牌，以防止其他车辆与其相撞，引起更大的交通事故`。这种将故障车辆停靠在路边紧急车道或设置
故障指标牌的方法，就是一种故障隔离。

 `分布式系统故障隔离`，就是采用一定的策略，以实现当某个模块故障时，不会影响其他模块继续提供服务，以保证整个系统的可用性。所以
 说，`故障隔离，可以避免分布式系统出现大规模的故障，甚至是瘫痪，降低损失`。
 
在分布式系统中，要实现故障隔离，`通常需要在进行系统设计时，提前对可能出现的故障进行预防`，以使得在出现故障后能实现故障隔离。此
外，由于是提前设计预防的，因此故障隔离还可以帮助我们快速定位故障点。 

#### 分布式故障隔离策略
分布式系统中的故障隔离策略有很多，大体上可以从两个维度来划分:
+ 一类是以系统功能模块为粒度进行隔离  
> 比如，通过系统功能 / 服务划分，将系统分为多个功能 / 服务模块，各个功能 / 服务模块之间实现松耦合，即一个功能 / 服务模块出现
>故障，不会影响其他功能 / 服务模块，根据功能模块或服务由线程执行还是进程执行，通常分为线程级隔离、进程级隔离。
+ 另一类是，通过资源隔离来实现  
> 比如，系统中各个模块拥有自己独立的资源，不会发生资源争抢，从而大大提升系统性能。根据资源所属粒度，通常包括进程级隔
>离（比如采用容器隔离）、虚拟机隔离、服务器隔离和机房隔离等。

基于这个分类，接下来，讲述三种比较常见的故障隔离策略，包括以功能模块为粒度进行隔离的线程级隔离和进程级隔离，以及以资源
为隔离维度的资源隔离。
##### 线程级隔离
线程级故障隔离，是`指使用不同的线程池处理不同的请求任务`. 某种请求任务出现故障时，负责其他请求任务的线程池不会受到影响，即会继续提
供服务，从而实现故障的隔离

```
以电商购物平台为例，假设初期运行在单台机器的一个进程中，在这个进程中有三个线程池，分别负责订单任务、支付任务和配送任务。这样，
当订单请求出现故障时，不会影响已下单用户的支付和仓库配送服务。
```

`线程级的故障隔离策略，在生产环境中较为常用，尤其对于单体应用（单进程多线程的应用）`。在单体应用场景下，应用被单个进程执行，但单进
程中包括多个线程，因此该场景下，只需要实现线程级隔离即可，实现简单、效果好，因此是一种很常用的方式。

+ 线程间通信  
>系统实现线程级隔离后，线程间的通信通常使用共享变量来实现。简单地说，共享变量就是一个进程中的全局变量，在进程的各个线程间可以
同时使用。这种通信方式，实现简单且效果明显。

##### 进程级隔离
随着业务逐渐扩大，业务系统也会越来越复杂，单体应用可能无法满足公司与用户的需求，这时候就需要对系统进行拆分。

`一种常用的方式就是，将系统按照功能分为不同的进程，分布到相同或不同的机器中`. 如果系统的进程分布到不同机器上的话，从资源的角度来
看，也可以说成是主机级的故障隔离。因为从另一个层面看，`系统确实分布到了不同机器上，当某个机器出现故障时，不会对其他机器造成影响`。

电商购物平台可以分为订单系统、支付系统和配送系统三部分。这三个子系统可以采用三个不同的进程来服务用户。某一个子系统出现故障，都不
会导致其他系统不可用。

+ 进程间通信 
>系统实现进程级隔离后，进程间的协同必须通过进程间通信（IPC）来实现。进程间通信有很多方式，大体可以分为以下两类：
>+ 如果进程都在同一台机器上，则可以通过管道、消息队列、信号量、共享内存等方式，来实现；  
>+ 如果进程分布在不同机器上，则可以通过远程调用来实现  

##### 资源隔离
资源隔离就是将分布式系统的所有资源分成几个部分，每部分资源负责一个模块，这样系统各个模块就不会争抢资源，即资源之间互不干扰。这种方
式不仅可以提高硬件资源利用率，也便于系统的维护与管理，可以大幅提升系统性能。

微服务就是一个典型的例子, 在微服务的理念中，是尽可能将服务最小化，服务与服务之间进行解耦合，包括运行环境的相互隔离等。比如，现在
通常采用容器进行隔离, Mesos、Kubernetes 等可实现容器管理与调度，而 Mesos 和 Kuberntes 的上层应用很多都是微服务。

实际上，在微服务框架中，一个服务通常对应一个容器，而一个容器其实就是操作系统中一个进程，不同容器负责不同的服务，就类似于刚才所
讲的：不同进程负责系统不同的功能模块。

如果将电商购物平台微服务化，则可以启动三个容器，分别负责订单服务、支付服务和配送服务。一个容器对应一个进程，因此`微服务框架本
质上还是一种进程级故障隔离策略`。

但与进程级隔离不同的是，微服务框架采用容器进行故障隔离。容器虽然本质上是操作系统的一个进程，但具备普通进程不具备的特性，比如资源隔离
+ 一个普通进程有很大的计算或内存需求时，可能会占满物理机上所有的 CPU、内存资源，导致其他进程没有资源可用，引发进程间的资源争夺；
+ 但容器可以实现资源限制，让每个容器占用的资源都有一个上限，比如 CPU、内存，均会设置一个上限值，这个上限值限定了该容器的处理能力，
  就好比一台服务器具有资源上限值一样。因此，一个容器使用的资源不会影响其他容器的资源，从而避免资源争抢，提高性能。

`那到底什么是容器呢？ 容器是一种虚拟化技术，可以为应用提供一整套运行环境。容器通过限制自身使用的资源来实现资源隔离，从而让容器就]
像一个个的“集装箱”：容量固定，存放着任意的物品。`

目前，比较常用的容器是 Docker。Docker 主要使用 Linux 内核中的 Linux Cgroups 模块来设置容器的资源上限，包括 CPU、内存、磁盘、
网络带宽等。通过 Cgroups 模块，容器间就形成了资源隔离，从而避免了容器间的资源争夺，提升了系统性能。

`通过容器进行资源隔离后，需要容器进行网络配置来进行容器间的通信。比如，Docker 默认是通过建立虚拟网桥来实现容器间通信的`






 
 



